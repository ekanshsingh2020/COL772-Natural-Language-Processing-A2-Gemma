{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:23:01.057600Z","iopub.status.busy":"2024-04-01T16:23:01.056898Z","iopub.status.idle":"2024-04-01T16:23:18.784737Z","shell.execute_reply":"2024-04-01T16:23:18.783675Z","shell.execute_reply.started":"2024-04-01T16:23:01.057563Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'gemma_pytorch'...\n","remote: Enumerating objects: 133, done.\u001b[K\n","remote: Counting objects: 100% (65/65), done.\u001b[K\n","remote: Compressing objects: 100% (41/41), done.\u001b[K\n","remote: Total 133 (delta 40), reused 35 (delta 23), pack-reused 68\u001b[K\n","Receiving objects: 100% (133/133), 2.15 MiB | 5.89 MiB/s, done.\n","Resolving deltas: 100% (67/67), done.\n"]}],"source":["# Setup the environment\n","!pip install -q -U immutabledict sentencepiece \n","!git clone https://github.com/google/gemma_pytorch.git\n","!mkdir /kaggle/working/gemma/\n","!mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/gemma/\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:23:18.787998Z","iopub.status.busy":"2024-04-01T16:23:18.787261Z","iopub.status.idle":"2024-04-01T16:25:02.676271Z","shell.execute_reply":"2024-04-01T16:25:02.675350Z","shell.execute_reply.started":"2024-04-01T16:23:18.787959Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"data":{"text/plain":["\"The Golden Gate Bridge:\\n- Take a scenic drive across the Golden Gate Bridge or a boat ride underneath it.\\nThe Golden Gate Bridge is a must-see attraction in San Francisco's Bay Area.\\n\\nAltos and Monterey:\\n- Visit the charming town of Altos' historical downtown and the world-renowned Monterey Bay Aquarium.\\n\\nLake Tahoe:\\n- Hike or drive to the stunning Lake Tahoe, a jewel of the Sierra Nevada Mountains.\\n\\nSan Francisco:\\n- Explore the Golden\""]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import sys \n","sys.path.append(\"/kaggle/working/gemma_pytorch/\") \n","from gemma.config import GemmaConfig, get_config_for_7b, get_config_for_2b\n","from gemma.model import GemmaForCausalLM\n","from gemma.tokenizer import Tokenizer\n","import contextlib\n","import os\n","import torch\n","import json\n","import random\n","import pandas as pd\n","\n","# Load the model\n","VARIANT = \"7b-it-quant\" \n","MACHINE_TYPE = \"cuda\" \n","weights_dir = '/kaggle/input/gemma/pytorch/7b-it-quant/2' \n","\n","@contextlib.contextmanager\n","def _set_default_tensor_type(dtype: torch.dtype):\n","  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n","  torch.set_default_dtype(dtype)\n","  yield\n","  torch.set_default_dtype(torch.float)\n","\n","model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()\n","model_config.tokenizer = os.path.join(weights_dir, \"tokenizer.model\")\n","model_config.quant = \"quant\" in VARIANT\n","\n","device = torch.device(MACHINE_TYPE)\n","with _set_default_tensor_type(model_config.get_dtype()):\n","  model = GemmaForCausalLM(model_config)\n","  ckpt_path = os.path.join(weights_dir, f'gemma-{VARIANT}.ckpt')\n","  model.load_weights(ckpt_path)\n","  model = model.to(device).eval()\n","\n","\n","\n","# Use the model\n","\n","USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n\"\n","MODEL_CHAT_TEMPLATE = \"<start_of_turn>model\\n{prompt}<end_of_turn>\\n\"\n","\n","prompt = (\n","    USER_CHAT_TEMPLATE.format(\n","        prompt=\"What is a good place for travel in the US?\"\n","    )\n","    + MODEL_CHAT_TEMPLATE.format(prompt=\"California.\")\n","    + USER_CHAT_TEMPLATE.format(prompt=\"What can I do in California?\")\n","    + \"<start_of_turn>model\\n\"\n",")\n","\n","model.generate(\n","    USER_CHAT_TEMPLATE.format(prompt=prompt),\n","    device=device,\n","    output_len=100,\n",")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:25:02.678364Z","iopub.status.busy":"2024-04-01T16:25:02.677956Z","iopub.status.idle":"2024-04-01T16:25:02.689547Z","shell.execute_reply":"2024-04-01T16:25:02.688503Z","shell.execute_reply.started":"2024-04-01T16:25:02.678339Z"},"trusted":true},"outputs":[],"source":["class PromptGenerator(object):\n","    def __init__(self):\n","        \"\"\"\n","        Setup generation parameters for Gemma.\n","        \"\"\"\n","        self.output_len = 20\n","        self.temperature = 0.0\n","        self.top_p = 1.0\n","\n","    def create_prompt(self, sample):\n","        \"\"\"\n","        Input sample is a dictionary consisting of following fields\n","        'table': A dict containing table data and meta-data same as in Assignment 2\n","        'question': A python string for the question on the table.\n","        \n","        The function must return the prompt as a python string.\n","        \"\"\"\n","        # Example prompt\n","        prompt = \"\"\"Read the following table and answer the related question.\\n\\n\"\"\"\n","        prompt += 'TABLE:\\n'\n","        prompt += ','.join(\n","            [f'\"{cc}\"' for cc in sample['table']['cols']]\n","        ) + '\\n'\n","        for row in sample['table']['rows']:\n","            prompt += ','.join(\n","                [f'\"{rr}\"' for rr in row]\n","            ) + '\\n'\n","        prompt += '\\n'\n","        prompt += 'QUESTION: ' + sample['question'] + '\\n'\n","        prompt += 'Now give the correct column and the correct rows'\n","\n","        return prompt\n","    \n","    def create_prompt_shot(self, sample):\n","        \"\"\"\n","        Input sample is a dictionary consisting of following fields\n","        'table': A dict containing table data and meta-data same as in Assignment 2\n","        'question': A python string for the question on the table.\n","        \n","        The function must return the prompt as a python string.\n","        \"\"\"\n","        # Example prompt\n","        prompt = \"\"\"Read the following table and answer the related question.\\n\\n\"\"\"\n","        prompt += 'TABLE:\\n'\n","        prompt += ','.join(\n","            [f'\"{cc}\"' for cc in sample['table']['cols']]\n","        ) + '\\n'\n","        for row in sample['table']['rows']:\n","            prompt += ','.join(\n","                [f'\"{rr}\"' for rr in row]\n","            ) + '\\n'\n","        prompt += '\\n'\n","        prompt += 'QUESTION: ' + sample['question'] + '\\n'\n","#         print(sample['label_col'])\n","        prompt += 'The correct column is ' + sample['label_col'] + '\\n'\n","        # convert sample['label_rows'] to string\n","\n","        prompt += 'The correct rows are ' + ', '.join([str(rr) for rr in sample['label_rows']]) + '\\n'\n","        prompt += '\\n'\n","\n","        return prompt\n","    \n","    def post_process(self, gen_text):\n","        \"\"\"\n","        Input gen_text is a python string generated by Gemma for the prompt.\n","        \n","        The function must return a single python tuple (int, string)\n","        indicating the row and the column of the answer cell.\n","        \"\"\"\n","#         gen_text = gen_text.split('\\n')[0]\n","#         # now remove the first 4 words from the generated text\n","#         gen_text = ' '.join(gen_text.split()[4:])\n","        return gen_text\n","\n","    "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:25:02.692996Z","iopub.status.busy":"2024-04-01T16:25:02.692457Z","iopub.status.idle":"2024-04-01T16:25:02.717993Z","shell.execute_reply":"2024-04-01T16:25:02.717064Z","shell.execute_reply.started":"2024-04-01T16:25:02.692957Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'question': \"What is the name of the subject who ran in the general election for Queen Anne's County State's Attorney?\",\n"," 'table': {'cols': ['Year', 'Office', 'Election', 'Subject', 'Party', 'Votes'],\n","  'rows': [['2002',\n","    \"Queen Anne's County State's Attorney\",\n","    'General',\n","    'Frank Kratovil',\n","    'Democratic',\n","    '9,169'],\n","   ['2006',\n","    \"Queen Anne's County State's Attorney\",\n","    'General',\n","    'Frank Kratovil',\n","    'Democratic',\n","    '13,894'],\n","   ['2008',\n","    \"U.S. House , Maryland's 1st district\",\n","    'Primary',\n","    'Frank Kratovil',\n","    'Democratic',\n","    '28,566'],\n","   ['2008',\n","    \"U.S. House , Maryland's 1st district\",\n","    'General',\n","    'Frank Kratovil',\n","    'Democratic',\n","    '177,065'],\n","   ['2010',\n","    \"U.S. House , Maryland's 1st district\",\n","    'General',\n","    'Andy Harris',\n","    'Republican',\n","    '155,118']],\n","  'types': ['real', 'text', 'text', 'text', 'text', 'real'],\n","  'caption': 'Electoral history'},\n"," 'label_col': 'Subject',\n"," 'label_row': [0, 1]}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["sample_shot = {\n","    \"question\":\"When was the opponent Poland and the match type EC -qualifier?\",\n","    \"table\":{\n","        \"cols\":[\"Date\",\"Location\",\"Opponenent\",\"Result\",\"Match type\"],\n","        \"rows\":[\n","            [\"29 March 2000\",\"Debrecen\",\"Poland\",\"0-0 (draw)\",\"friendly\"],\n","            [\"16 August 2000\",\"Budapest\",\"Austria\",\"1-1 (draw)\",\"friendly\"],\n","            [\"3 September 2000\",\"Budapest\",\"Italy\",\"2-2 (draw)\",\"WC -qualifier\"],\n","            [\"15 August 2001\",\"Budapest\",\"Germany\",\"2-5 (defeat)\",\"friendly\"],\n","            [\"1 September 2001\",\"Tbilisi\",\"Georgia\",\"1-3 (defeat)\",\"WC-qualifier\"],\n","            [\"5 September 2001\",\"Budapest\",\"Romania\",\"0-2 (defeat)\",\"WC-qualifier\"],\n","            [\"6 October 2001\",\"Parma\",\"Italy\",\"0-0 (draw)\",\"WC-qualifier\"],\n","            [\"14 November 2001\",\"Budapest\",\"Macedonia\",\"5-0 (win)\",\"friendly\"],\n","            [\"12 February 2002\",\"Larnaca\",\"Czech Rep.\",\"0-2 (defeat)\",\"friendly\"],\n","            [\"13 February 2002\",\"Limassol\",\"Switzerland\",\"1-2 (defeat)\",\"friendly\"],\n","            [\"8 May 2002\",\"P\\u00e9cs\",\"Croatia\",\"0-2 (defeat)\",\"friendly\"],\n","            [\"21 August 2002\",\"Budapest\",\"Spain\",\"1-1 (draw)\",\"friendly\"],\n","            [\"7 September 2002\",\"Reykjav\\u00edk\",\"Iceland\",\"2-0 (win)\",\"friendly\"],\n","            [\"12 October 2002\",\"Stockholm\",\"Sweden\",\"1-1 (draw)\",\"EC-qualifier\"],\n","            [\"16 October 2002\",\"Budapest\",\"San Marino\",\"3-0 (win)\",\"EC -qualifier\"],\n","            [\"20 November 2002\",\"Budapest\",\"Moldova\",\"1-1 (draw)\",\"friendly\"],\n","            [\"12 February 2003\",\"Larnaca\",\"Bulgaria\",\"0-1 (defeat)\",\"friendly\"],\n","            [\"29 March 2003\",\"Chorz\\u00f3w\",\"Poland\",\"0-0 (draw)\",\"EC -qualifier\"],\n","            [\"2 April 2003\",\"Budapest\",\"Sweden\",\"1-2 (defeat)\",\"EC -qualifier\"],\n","            [\"30 April 2003\",\"Budapest\",\"Luxembourg\",\"5-1 (win)\",\"friendly\"],\n","            [\"19 February 2004\",\"Limassol\",\"Latvia\",\"2-1 (win)\",\"friendly\"],\n","            [\"21 February 2004\",\"Limassol\",\"Romania\",\"0-3 (defeat)\",\"friendly\"],\n","            [\"9 February 2011\",\"Dubai\",\"Azerbaijan\",\"2-0 (win)\",\"friendly\"],\n","            [\"29 March 2011\",\"Amsterdam\",\"Netherlands\",\"3-5 (defeat)\",\"EC -qualifier\"],\n","            [\"3 June 2011\",\"Luxembourg\",\"Luxembourg\",\"1-0 (win)\",\"friendly\"]\n","        ],\n","        \"types\":[\"text\",\"text\",\"text\",\"text\",\"text\"],\n","        \"caption\":\"National team matches\",\n","    },\n","    \"label_col\":\"Date\",\n","    \"label_row\":[17]\n","}\n","sample_shot\n","\n","sample_shot2 = {\n","    \"question\":\"What is the total score when 7 is the average ranking?\",\n","    \"table\":{\n","        \"cols\":[\"Average Ranking\",\"Competitive Finish\",\"Couple\",\"Number Of Dances\",\"Total Score\",\"Average\"],\n","        \"rows\":[\n","            [\"1\",\"1\",\"Bridie & Craig\",\"15\",\"509\",\"35.9\"],\n","            [\"2\",\"3\",\"David & Karina\",\"12\",\"360\",\"30.0\"],\n","            [\"3\",\"4\",\"Patti & Sandro\",\"10\",\"295\",\"29.5\"],\n","            [\"4\",\"2\",\"Anh & Luda\",\"15\",\"421\",\"27.0\"],\n","            [\"5\",\"9\",\"Corinne & Csaba\",\"3\",\"77\",\"25.7\"],\n","            [\"6\",\"5\",\"Mark & Linda\",\"8\",\"204\",\"25.5\"],\n","            [\"7\",\"8\",\"Elka & Michael\",\"4\",\"100\",\"25.0\"],\n","            [\"8\",\"6\",\"James & Olya\",\"7\",\"169\",\"24.1\"],\n","            [\"9\",\"7\",\"Jessica & Serghei\",\"5\",\"120\",\"24.0\"]\n","        ],\n","        \"types\":[\"real\",\"real\",\"text\",\"real\",\"real\",\"text\"],\n","        \"caption\":\"Average Chart\"\n","    },\n","    \"label_col\":\"Total Score\",\n","    \"label_row\":[6]\n","}\n","sample_shot2\n","\n","sample_shot3 = {\n","    \"question\":\"What is the name of the subject who ran in the general election for Queen Anne's County State's Attorney?\",\n","    \"table\":{\n","        \"cols\":[\"Year\",\"Office\",\"Election\",\"Subject\",\"Party\",\"Votes\"],\n","        \"rows\":[\n","            [\"2002\",\"Queen Anne's County State's Attorney\",\"General\",\"Frank Kratovil\",\"Democratic\",\"9,169\"],\n","            [\"2006\",\"Queen Anne's County State's Attorney\",\"General\",\"Frank Kratovil\",\"Democratic\",\"13,894\"],\n","            [\"2008\",\"U.S. House , Maryland's 1st district\",\"Primary\",\"Frank Kratovil\",\"Democratic\",\"28,566\"],\n","            [\"2008\",\"U.S. House , Maryland's 1st district\",\"General\",\"Frank Kratovil\",\"Democratic\",\"177,065\"],\n","            [\"2010\",\"U.S. House , Maryland's 1st district\",\"General\",\"Andy Harris\",\"Republican\",\"155,118\"]],\n","        \"types\":[\"real\",\"text\",\"text\",\"text\",\"text\",\"real\"],\n","        \"caption\":\"Electoral history\"\n","    },\n","    \"label_col\":\"Subject\",\n","    \"label_row\":[0,1]\n","}\n","sample_shot3"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:25:02.719361Z","iopub.status.busy":"2024-04-01T16:25:02.719102Z","iopub.status.idle":"2024-04-01T16:25:02.730281Z","shell.execute_reply":"2024-04-01T16:25:02.729445Z","shell.execute_reply.started":"2024-04-01T16:25:02.719339Z"},"trusted":true},"outputs":[],"source":["# sample = {\n","#     \"question\":\"What is the sum of week(s) with an attendance of 30,751?\",\n","#     \"table\":{\n","#         \"cols\":[\"Week\",\"Date\",\"Opponent\",\"Result\",\"Attendance\"],\n","#         \"rows\":[\n","#             [\"1\",\"August 6, 1973\",\"San Francisco 49ers\",\"L 27\\u201316\",\"65,707\"],\n","#             [\"2\",\"August 11, 1973\",\"at Los Angeles Rams\",\"T 21\\u201321\",\"54,385\"],\n","#             [\"3\",\"August 19, 1973\",\"vs. Cincinnati Bengals at Columbus, Ohio\",\"W 24\\u20136\",\"73,421\"],\n","#             [\"4\",\"August 25, 1973\",\"vs. Atlanta Falcons at Knoxville\",\"W 20\\u201317\",\"40,831\"],\n","#             [\"5\",\"September 1, 1973\",\"Detroit Lions\",\"L 16\\u201313\",\"64,088\"],\n","#             [\"6\",\"September 8, 1973\",\"vs. New York Giants at Akron\",\"L 21\\u201310\",\"30,751\"]\n","#         ],\n","#         \"types\":[\"real\",\"text\",\"text\",\"text\",\"real\"],\n","#         \"caption\":\"Exhibition schedule\"\n","#     }\n","# }\n","# sample\n","# prompt_gen = PromptGenerator()\n","# prompt_act = prompt_gen.create_prompt(sample)\n","# prompt_shot = prompt_gen.create_prompt_shot(sample_shot)\n","# prompt_shot2 = prompt_gen.create_prompt_shot(sample_shot2)\n","# prompt = prompt_shot + prompt_shot2 + prompt_act\n","# print(prompt)\n","\n","# gen_text = model.generate(\n","#     USER_CHAT_TEMPLATE.format(prompt=prompt),\n","#     device=device,\n","#     output_len=prompt_gen.output_len,\n","#     temperature=prompt_gen.temperature,\n","#     top_p=prompt_gen.top_p,\n","# )\n","\n","# print(gen_text)\n","\n","# answer = prompt_gen.post_process(gen_text)\n","# answer"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:25:02.731440Z","iopub.status.busy":"2024-04-01T16:25:02.731206Z","iopub.status.idle":"2024-04-01T16:25:03.103678Z","shell.execute_reply":"2024-04-01T16:25:03.102866Z","shell.execute_reply.started":"2024-04-01T16:25:02.731420Z"},"trusted":true},"outputs":[],"source":["data = []\n","with open('/kaggle/input/a2-val/A2_val.jsonl', 'r') as f:\n","    for line in f:\n","        data.append(json.loads(line))\n","\n","# Sample 100 random samples\n","random.seed(42)\n","samples = random.sample(data, 20)\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:25:03.105292Z","iopub.status.busy":"2024-04-01T16:25:03.104995Z","iopub.status.idle":"2024-04-01T16:25:03.556313Z","shell.execute_reply":"2024-04-01T16:25:03.555168Z","shell.execute_reply.started":"2024-04-01T16:25:03.105266Z"},"trusted":true},"outputs":[{"ename":"TypeError","evalue":"can only concatenate str (not \"list\") to str","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate the answers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m prompt_generator \u001b[38;5;241m=\u001b[39m PromptGenerator()\n\u001b[0;32m----> 3\u001b[0m prompt_shot \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_prompt_shot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m prompt_shot2 \u001b[38;5;241m=\u001b[39m prompt_generator\u001b[38;5;241m.\u001b[39mcreate_prompt_shot(sample_shot2)\n\u001b[1;32m      5\u001b[0m prompt_shot3 \u001b[38;5;241m=\u001b[39m prompt_generator\u001b[38;5;241m.\u001b[39mcreate_prompt_shot(sample_shot3)\n","Cell \u001b[0;32mIn[3], line 56\u001b[0m, in \u001b[0;36mPromptGenerator.create_prompt_shot\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#         print(sample['label_col'])\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe correct column is \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_col\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 56\u001b[0m         prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThe correct rows are \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_row\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     57\u001b[0m         prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m prompt\n","\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"]}],"source":["# Generate the answers\n","prompt_generator = PromptGenerator()\n","prompt_shot = prompt_generator.create_prompt_shot(sample_shot)\n","prompt_shot2 = prompt_generator.create_prompt_shot(sample_shot2)\n","prompt_shot3 = prompt_generator.create_prompt_shot(sample_shot3)\n","answers = []\n","num=1\n","maxrow=0\n","for sample in samples:\n","    print(\"Sample number is \"+ str(num))\n","    print(\"Question is \"+ sample['question'])\n","    ## print the number of rows and columns in the table\n","#     print(\"Number of rows in the table is \"+ str(len(sample['table']['rows'])))\n","#     print(\"Number of columns in the table is \"+ str(len(sample['table']['cols'])))\n","    if len(sample['table']['rows']) > 100:\n","        sample['table']['rows'] = sample['table']['rows'][:100]\n","    cur_sample = {'question': sample['question'], 'table': sample['table']}\n","    maxrow = max(maxrow,len(sample['table']['rows']))\n","    prompt_act = prompt_generator.create_prompt(cur_sample)\n","    prompt = prompt_shot + prompt_shot2 + prompt_shot3 + prompt_act\n","    answer = model.generate(\n","        USER_CHAT_TEMPLATE.format(prompt=prompt),\n","        device=device,\n","        output_len=prompt_generator.output_len,\n","        temperature=prompt_generator.temperature,\n","        top_p=prompt_generator.top_p,\n","    )\n","#     print(\"Gen text is \"+ answer)\n","    answer = prompt_generator.post_process(answer)\n","    print(\"Answer got is \" + answer)\n","    print(\"Column should be \"+ sample['label_col'][0])\n","    print(\"Row should be \"+ sample['label_row'])\n","    print(\"===================================================================\")\n","#     answers.append(answer)\n","    num+=1\n","    del cur_sample\n","    del prompt_act\n","    del prompt\n","    del answer\n","\n","# Now find the accuracy of the model\n","# correct = 0\n","# for sample, answer in zip(samples, answers):\n","#     if sample['label_col'][0] == answer:\n","#         correct += 1\n","\n","# accuracy = correct / len(samples)\n","# print(\"accuracy is \"+ accuracy)\n","# print(\"maxrow is \"+ maxrow)\n","# print(\"correct ans is \"+ correct)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:25:03.557085Z","iopub.status.idle":"2024-04-01T16:25:03.557405Z","shell.execute_reply":"2024-04-01T16:25:03.557259Z","shell.execute_reply.started":"2024-04-01T16:25:03.557246Z"},"trusted":true},"outputs":[],"source":["print(correct)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4708304,"sourceId":7996575,"sourceType":"datasetVersion"},{"datasetId":4708386,"sourceId":7996680,"sourceType":"datasetVersion"},{"modelInstanceId":8749,"sourceId":11359,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
